# ==============================================================================
# å·¥å…· 1: Word æ–‡ä»¶è‡ªå‹•æ¨™è¨˜è¼”åŠ©å·¥å…·
# æª”æ¡ˆåç¨±: auto_bookmark_helper.py
# ç”¨é€”: æƒæ Word æ–‡ä»¶,æ‰¾å‡ºæ‰€æœ‰å¯èƒ½éœ€è¦æ¨™è¨˜çš„æ¬„ä½,ä¸¦å»ºè­°æ›¸ç±¤åç¨±
# ==============================================================================

import os
import re
from pathlib import Path
import yaml

try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("âš ï¸ python-docx æœªå®‰è£,å˜—è©¦ä½¿ç”¨ COM æ¨¡å¼...")

try:
    import win32com.client
    COM_AVAILABLE = True
except ImportError:
    COM_AVAILABLE = False


def extract_potential_fields_from_docx(file_path):
    """
    å¾ Word æ–‡ä»¶ä¸­æå–å¯èƒ½éœ€è¦æ¨™è¨˜çš„æ¬„ä½
    ä½¿ç”¨å•Ÿç™¼å¼è¦å‰‡è­˜åˆ¥:
    1. å†’è™Ÿå¾Œçš„å…§å®¹ (ä¾‹å¦‚: "ç”¢å“åç¨±: _____")
    2. è¡¨æ ¼ä¸­çš„ç©ºç™½å„²å­˜æ ¼
    3. ç‰¹å®šæ ¼å¼çš„æ–‡å­— (ä¾‹å¦‚: [å¾…å¡«å…¥])
    """
    if not DOCX_AVAILABLE:
        return None
    
    doc = Document(file_path)
    potential_fields = []
    
    # è¦å‰‡ 1: å°‹æ‰¾ "æ¬„ä½åç¨±: _____" æˆ– "æ¬„ä½åç¨±: [ç©ºç™½]" æ ¼å¼
    pattern_colon = re.compile(r'([^\n:ï¼š]+)[ï¼š:]\s*(_+|\[.*?\]|ã€.*?ã€‘|ï¼¿+|\s{3,}|$)')
    
    # è¦å‰‡ 2: å°‹æ‰¾å¸¸è¦‹æ¬„ä½é—œéµå­—
    field_keywords = [
        'åç¨±', 'ç‰ˆæœ¬', 'å‹è™Ÿ', 'è¦æ ¼', 'æè¿°', 'èªªæ˜',
        'CPU', 'è¨˜æ†¶é«”', 'ç¡¬ç¢Ÿ', 'å„²å­˜', 'ä½œæ¥­ç³»çµ±', 
        'æ—¥æœŸ', 'æ™‚é–“', 'é ç®—', 'é‡‘é¡', 'æ•¸é‡',
        'è² è²¬äºº', 'è¯çµ¡', 'é›»è©±', 'åœ°å€', 'Email'
    ]
    
    paragraph_index = 0
    for para in doc.paragraphs:
        text = para.text.strip()
        if not text:
            continue
        
        paragraph_index += 1
        
        # æª¢æŸ¥å†’è™Ÿæ ¼å¼
        matches = pattern_colon.findall(text)
        for field_name, placeholder in matches:
            field_name = field_name.strip()
            if len(field_name) < 30:  # é¿å…æŠ“åˆ°å¤ªé•·çš„å¥å­
                potential_fields.append({
                    'type': 'paragraph',
                    'location': f'æ®µè½ {paragraph_index}',
                    'field_name': field_name,
                    'context': text[:100],
                    'suggested_bookmark': generate_bookmark_name(field_name),
                    'confidence': 'high' if placeholder else 'medium'
                })
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«é—œéµå­—
        for keyword in field_keywords:
            if keyword in text and len(text) < 50:
                if not any(pf['field_name'] == text for pf in potential_fields):
                    potential_fields.append({
                        'type': 'keyword',
                        'location': f'æ®µè½ {paragraph_index}',
                        'field_name': text,
                        'context': text,
                        'suggested_bookmark': generate_bookmark_name(text),
                        'confidence': 'medium'
                    })
    
    # æª¢æŸ¥è¡¨æ ¼
    table_index = 0
    for table in doc.tables:
        table_index += 1
        for row_idx, row in enumerate(table.rows):
            for col_idx, cell in enumerate(row.cells):
                cell_text = cell.text.strip()
                
                # è¡¨æ ¼æ¬„ä½åç¨±é€šå¸¸åœ¨ç¬¬ä¸€åˆ—æˆ–ç¬¬ä¸€æ¬„
                if row_idx == 0 or col_idx == 0:
                    if cell_text and any(kw in cell_text for kw in field_keywords):
                        # æ‰¾å°æ‡‰çš„å€¼å„²å­˜æ ¼
                        value_cell = None
                        if col_idx == 0 and len(row.cells) > 1:
                            value_cell = row.cells[1].text.strip()
                        elif row_idx == 0 and table_index < len(table.rows):
                            value_cell = table.rows[row_idx + 1].cells[col_idx].text.strip()
                        
                        if not value_cell or len(value_cell) < 3:  # ç©ºç™½æˆ–å¾ˆçŸ­ = å¯èƒ½éœ€è¦å¡«å…¥
                            potential_fields.append({
                                'type': 'table',
                                'location': f'è¡¨æ ¼ {table_index}, åˆ— {row_idx + 1}, æ¬„ {col_idx + 1}',
                                'field_name': cell_text,
                                'context': cell_text,
                                'suggested_bookmark': generate_bookmark_name(cell_text),
                                'confidence': 'high'
                            })
    
    return potential_fields


def generate_bookmark_name(field_name):
    """
    å¾ä¸­æ–‡æ¬„ä½åç¨±ç”Ÿæˆè‹±æ–‡æ›¸ç±¤åç¨±
    """
    # é å®šç¾©å¸¸è¦‹å°æ‡‰
    mapping = {
        'ç”¢å“åç¨±': 'ProductName',
        'ç”¢å“å‹è™Ÿ': 'ProductModel',
        'ç‰ˆæœ¬': 'Version',
        'ç‰ˆæœ¬è™Ÿ': 'VersionNumber',
        'æè¿°': 'Description',
        'èªªæ˜': 'Description',
        'CPU': 'CPU',
        'è™•ç†å™¨': 'CPU',
        'è¨˜æ†¶é«”': 'Memory',
        'RAM': 'Memory',
        'ç¡¬ç¢Ÿ': 'Storage',
        'å„²å­˜ç©ºé–“': 'Storage',
        'ä½œæ¥­ç³»çµ±': 'OS',
        'é–‹å§‹æ—¥æœŸ': 'StartDate',
        'çµæŸæ—¥æœŸ': 'EndDate',
        'é ç®—': 'Budget',
        'é‡‘é¡': 'Amount',
        'è² è²¬äºº': 'Owner',
        'è¯çµ¡äºº': 'Contact',
        'é›»è©±': 'Phone',
        'åœ°å€': 'Address',
        'éƒµä»¶': 'Email',
        'Email': 'Email',
    }
    
    # å…ˆå˜—è©¦ç›´æ¥å°æ‡‰
    if field_name in mapping:
        return mapping[field_name]
    
    # ç§»é™¤å¸¸è¦‹å¾Œç¶´
    clean_name = field_name.replace('åç¨±', '').replace('ç·¨è™Ÿ', 'ID').strip()
    if clean_name in mapping:
        return mapping[clean_name]
    
    # è½‰æ›ç‚ºæ‹¼éŸ³æˆ–ä¿æŒè‹±æ–‡
    # é€™è£¡ç°¡åŒ–è™•ç†,å¯¦éš›å¯æ•´åˆ pypinyin å¥—ä»¶
    # å¦‚æœåŒ…å«è‹±æ–‡,ä¿ç•™è‹±æ–‡
    english_only = re.sub(r'[^a-zA-Z0-9]', '', field_name)
    if english_only:
        return english_only[:30]  # é™åˆ¶é•·åº¦
    
    # è½‰ç‚ºæ‹¼éŸ³é¦–å­—æ¯ (ç°¡åŒ–ç‰ˆ,å»ºè­°ä½¿ç”¨ pypinyin)
    return 'Field_' + ''.join(filter(str.isalnum, field_name))[:20]


def generate_mapping_suggestions(potential_fields, ssot_path='ssot/master.yaml'):
    """
    æ ¹æ“š SSOT çµæ§‹,å»ºè­°æ¬„ä½å°æ‡‰
    """
    if not os.path.exists(ssot_path):
        return potential_fields
    
    with open(ssot_path, 'r', encoding='utf-8') as f:
        ssot = yaml.safe_load(f)
    
    # æ‰å¹³åŒ– SSOT çµæ§‹
    ssot_fields = flatten_dict(ssot)
    
    # ç‚ºæ¯å€‹æ½›åœ¨æ¬„ä½æ‰¾æœ€ä½³åŒ¹é…
    for field in potential_fields:
        field_lower = field['field_name'].lower()
        best_match = None
        best_score = 0
        
        for ssot_key, ssot_value in ssot_fields.items():
            # ç°¡å–®ç›¸ä¼¼åº¦è¨ˆç®—
            score = calculate_similarity(field_lower, ssot_key.lower())
            if score > best_score:
                best_score = score
                best_match = ssot_key
        
        if best_score > 0.3:  # ç›¸ä¼¼åº¦é–¾å€¼
            field['suggested_ssot_path'] = best_match
            field['ssot_value'] = ssot_fields[best_match]
        else:
            field['suggested_ssot_path'] = None
    
    return potential_fields


def flatten_dict(d, parent_key='', sep='.'):
    """æ‰å¹³åŒ–åµŒå¥—å­—å…¸"""
    items = []
    for k, v in d.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.extend(flatten_dict(v, new_key, sep=sep).items())
        elif isinstance(v, list):
            # è·³éåˆ—è¡¨
            continue
        else:
            items.append((new_key, v))
    return dict(items)


def calculate_similarity(text1, text2):
    """ç°¡å–®çš„æ–‡å­—ç›¸ä¼¼åº¦è¨ˆç®—"""
    # æª¢æŸ¥é—œéµå­—åŒ¹é…
    keywords_map = {
        'name': ['åç¨±', 'name'],
        'version': ['ç‰ˆæœ¬', 'version'],
        'cpu': ['cpu', 'è™•ç†å™¨', 'processor'],
        'memory': ['è¨˜æ†¶é«”', 'memory', 'ram'],
        'storage': ['ç¡¬ç¢Ÿ', 'å„²å­˜', 'storage', 'disk'],
        'os': ['ä½œæ¥­ç³»çµ±', 'os', 'operating'],
    }
    
    for key, keywords in keywords_map.items():
        if any(kw in text1 for kw in keywords) and any(kw in text2 for kw in keywords):
            return 0.8
    
    # ç°¡å–®å­—ä¸²åŒ…å«
    if text1 in text2 or text2 in text1:
        return 0.5
    
    return 0.0


def export_to_yaml(potential_fields, template_name, output_path='mapping/auto_generated_mapping.yaml'):
    """
    å°‡å»ºè­°çš„æ¬„ä½å°æ‡‰åŒ¯å‡ºç‚º YAML æ ¼å¼
    """
    mapping = {
        'mapping_version': '1.0.0',
        'last_updated': '2025-11-13',
        'word_mappings': {
            template_name: {
                'file_path': f'templates/{template_name}.docx',
                'mappings': {}
            }
        }
    }
    
    for field in potential_fields:
        if field.get('suggested_ssot_path'):
            bookmark = field['suggested_bookmark']
            ssot_path = field['suggested_ssot_path']
            mapping['word_mappings'][template_name]['mappings'][ssot_path] = bookmark
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        yaml.dump(mapping, f, allow_unicode=True, sort_keys=False)
    
    return output_path


def generate_report(potential_fields, output_path='output/bookmark_suggestions.txt'):
    """
    ç”¢ç”Ÿäººé¡å¯è®€çš„å ±å‘Š
    """
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("Word æ–‡ä»¶è‡ªå‹•æ¨™è¨˜å»ºè­°å ±å‘Š\n")
        f.write("=" * 80 + "\n\n")
        
        # æŒ‰ä¿¡å¿ƒåº¦åˆ†çµ„
        high_conf = [f for f in potential_fields if f['confidence'] == 'high']
        medium_conf = [f for f in potential_fields if f['confidence'] == 'medium']
        
        f.write(f"ğŸ“Š çµ±è¨ˆè³‡è¨Š:\n")
        f.write(f"  â€¢ ç¸½å…±æ‰¾åˆ° {len(potential_fields)} å€‹æ½›åœ¨æ¬„ä½\n")
        f.write(f"  â€¢ é«˜ä¿¡å¿ƒåº¦: {len(high_conf)} å€‹\n")
        f.write(f"  â€¢ ä¸­ä¿¡å¿ƒåº¦: {len(medium_conf)} å€‹\n")
        f.write(f"  â€¢ å·²å»ºè­° SSOT å°æ‡‰: {len([f for f in potential_fields if f.get('suggested_ssot_path')])} å€‹\n\n")
        
        f.write("=" * 80 + "\n")
        f.write("é«˜ä¿¡å¿ƒåº¦æ¬„ä½ (å»ºè­°å„ªå…ˆæ¨™è¨˜)\n")
        f.write("=" * 80 + "\n\n")
        
        for idx, field in enumerate(high_conf, 1):
            f.write(f"{idx}. {field['field_name']}\n")
            f.write(f"   ä½ç½®: {field['location']}\n")
            f.write(f"   é¡å‹: {field['type']}\n")
            f.write(f"   å»ºè­°æ›¸ç±¤åç¨±: {field['suggested_bookmark']}\n")
            if field.get('suggested_ssot_path'):
                f.write(f"   å»ºè­° SSOT è·¯å¾‘: {field['suggested_ssot_path']}\n")
                f.write(f"   ç›®å‰ SSOT å€¼: {field.get('ssot_value', 'N/A')}\n")
            f.write(f"   ä¸Šä¸‹æ–‡: {field['context']}\n")
            f.write("\n")
        
        if medium_conf:
            f.write("=" * 80 + "\n")
            f.write("ä¸­ä¿¡å¿ƒåº¦æ¬„ä½ (è«‹æ‰‹å‹•ç¢ºèª)\n")
            f.write("=" * 80 + "\n\n")
            
            for idx, field in enumerate(medium_conf, 1):
                f.write(f"{idx}. {field['field_name']}\n")
                f.write(f"   ä½ç½®: {field['location']}\n")
                f.write(f"   å»ºè­°æ›¸ç±¤åç¨±: {field['suggested_bookmark']}\n")
                if field.get('suggested_ssot_path'):
                    f.write(f"   å»ºè­° SSOT è·¯å¾‘: {field['suggested_ssot_path']}\n")
                f.write("\n")
    
    return output_path


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Word æ–‡ä»¶è‡ªå‹•æ¨™è¨˜è¼”åŠ©å·¥å…·')
    parser.add_argument('file_path', help='Word æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--template-name', default='auto_detected', help='æ¨¡æ¿åç¨±')
    parser.add_argument('--ssot', default='ssot/master.yaml', help='SSOT æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--output-report', default='output/bookmark_suggestions.txt', help='å ±å‘Šè¼¸å‡ºè·¯å¾‘')
    parser.add_argument('--output-mapping', default='mapping/auto_generated_mapping.yaml', help='å°æ‡‰è¡¨è¼¸å‡ºè·¯å¾‘')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("Word æ–‡ä»¶è‡ªå‹•æ¨™è¨˜è¼”åŠ©å·¥å…·")
    print("=" * 80)
    print()
    
    if not DOCX_AVAILABLE and not COM_AVAILABLE:
        print("âŒ éŒ¯èª¤: éœ€è¦å®‰è£ python-docx æˆ– pywin32")
        print("   pip install python-docx")
        return
    
    if not os.path.exists(args.file_path):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {args.file_path}")
        return
    
    print(f"ğŸ“‚ åˆ†ææ–‡ä»¶: {args.file_path}")
    print()
    
    try:
        # æå–æ½›åœ¨æ¬„ä½
        print("ğŸ” æƒææ–‡ä»¶,å°‹æ‰¾æ½›åœ¨æ¬„ä½...")
        potential_fields = extract_potential_fields_from_docx(args.file_path)
        
        if not potential_fields:
            print("âš ï¸  æœªæ‰¾åˆ°æ½›åœ¨æ¬„ä½")
            return
        
        print(f"âœ… æ‰¾åˆ° {len(potential_fields)} å€‹æ½›åœ¨æ¬„ä½")
        print()
        
        # å»ºè­° SSOT å°æ‡‰
        print("ğŸ”— åˆ†æ SSOT å°æ‡‰...")
        potential_fields = generate_mapping_suggestions(potential_fields, args.ssot)
        matched = len([f for f in potential_fields if f.get('suggested_ssot_path')])
        print(f"âœ… å»ºè­°äº† {matched} å€‹ SSOT å°æ‡‰")
        print()
        
        # ç”¢ç”Ÿå ±å‘Š
        print("ğŸ“ ç”¢ç”Ÿå ±å‘Š...")
        report_path = generate_report(potential_fields, args.output_report)
        print(f"âœ… å ±å‘Šå·²å„²å­˜: {report_path}")
        print()
        
        # åŒ¯å‡ºå°æ‡‰è¡¨
        print("ğŸ’¾ åŒ¯å‡ºå°æ‡‰è¡¨...")
        mapping_path = export_to_yaml(potential_fields, args.template_name, args.output_mapping)
        print(f"âœ… å°æ‡‰è¡¨å·²å„²å­˜: {mapping_path}")
        print()
        
        print("=" * 80)
        print("âœ… å®Œæˆ!")
        print("=" * 80)
        print()
        print("ğŸ“‹ ä¸‹ä¸€æ­¥:")
        print(f"  1. æŸ¥çœ‹å ±å‘Š: {report_path}")
        print(f"  2. æª¢æŸ¥å°æ‡‰è¡¨: {mapping_path}")
        print("  3. åœ¨ Word ä¸­æ‰‹å‹•å»ºç«‹æ›¸ç±¤ (æˆ–ä½¿ç”¨æ‰¹æ¬¡å»ºç«‹å·¥å…·)")
        print("  4. åŸ·è¡Œæ–‡ä»¶ç”¢ç”Ÿæ¸¬è©¦")
        
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
